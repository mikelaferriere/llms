---
# NOTE: This is my GPU setup with my indexes. Make sure they match up to yours
# index 0: 3070 (9652988c-23cb-3d44-92f1-fe4b3189f334)
# index 1: 3060 ti (c5bc98c1-e7c9-a438-3cc5-56362e4eab24)
# index 2: 3060 (8b6de0bb-89ad-1f78-1c8b-34f0e740e1ca)
# index 3: 3060 (93546bb2-97df-8ac3-2941-6e8be8aef53c)
# index 4: 2060 (988d240c-f178-4b8f-eb54-d831f3d0f1a5)

version: '3.8'
services:
  tabby:
    container_name: tabby
    restart: always
    user: 1000:1000
    # This is to disable watchtower if it is being run on the current system
    labels:
      - "com.centurylinklabs.watchtower.enable=false"
    build:
      context: ./tabby
      dockerfile: ./Dockerfile
      args:
        CUDA_VERSION: 12.3.0
        RUST_TOOLCHAIN: 1.73
    command: serve --model TabbyML/DeepseekCoder-6.7B --device cuda
    volumes:
      - "./.tabby:/data"
      - "./projects:/projects"
    environment:
      TABBY_DISABLE_USAGE_COLLECTION: 1
      RUST_BACKTRACE: full
      LLAMA_CPP_PARALLELISM: 1
    ports:
      - 8080:8080
    deploy:
      resources:
        reservations:
           devices:
              - driver: nvidia
                device_ids: ['1']
                capabilities: [gpu]

  text-generation-webui:
    container_name: text-generation-webui
    user: 1000:1000
    # This is to disable watchtower if it is being run on the current system
    labels:
      - "com.centurylinklabs.watchtower.enable=false"
    build:
      context: ./text-generation-webui
      dockerfile: ./docker/nvidia/Dockerfile
      args:
        # specify which cuda version your card supports: https://developer.nvidia.com/cuda-gpus
        TORCH_CUDA_ARCH_LIST: ${TORCH_CUDA_ARCH_LIST:-7.5}
        WEBUI_VERSION: ${WEBUI_VERSION:-HEAD}

        # Comma separated extensions to build
        BUILD_EXTENSIONS: "openai"

        APP_GID: 1000
        APP_UID: 1000
    environment:
      # by default the Dockerfile specifies these versions: 3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6+PTX
      # however for me to work i had to specify the exact version for my card ( 2060 ) it was 7.5
      # https://developer.nvidia.com/cuda-gpus you can find the version for your card here
      TORCH_CUDA_ARCH_LIST: 7.5

      # the port the webui binds to on the host
      HOST_PORT: 7860

      # the port the webui binds to inside the container
      CONTAINER_PORT: 7860

      # the port the api binds to on the host
      HOST_API_PORT: 5000

      # the port the api binds to inside the container
      CONTAINER_API_PORT: 5000

      # the port the api binds to on the host
      HOST_STREAMING_PORT: 5005

      # the port the api binds to inside the container
      CONTAINER_STREAMING_PORT: 5005

      # Comma separated extensions to build
      BUILD_EXTENSIONS: "api,gallery,openai"

      # Set APP_RUNTIME_GID to an appropriate host system group to enable access to mounted volumes 
      # You can find your current host user group id with the command `id -g`
      APP_RUNTIME_GID: 1000

      # override default app build permissions (handy for deploying to cloud)
      APP_GID: 1000
      APP_UID: 1000

      # You will first need to run this "bare" CLI_ARGs so you can download the models via the UI.
      # Once you do that, you can specify the model directly and it will load up on start.
      # You can also download the models outside of this container in the proper location (see volumes)

      CLI_ARGS: "--api --listen"
      # CLI_ARGS: "--api --listen --model models/TheBloke_OpenHermes-2.5-Mistral-7B-16k-GPTQ"

      # Set cache env
      TRANSFORMERS_CACHE: /home/app/text-generation-webui/cache/
      HF_HOME: /home/app/text-generation-webui/cache/

    ports:
      - "${HOST_PORT:-7860}:${CONTAINER_PORT:-7860}"
      - "${HOST_API_PORT:-5000}:${CONTAINER_API_PORT:-5000}"
      - "${HOST_STREAMING_PORT:-5005}:${CONTAINER_STREAMING_PORT:-5005}"
    stdin_open: true
    tty: true
    volumes:
      - ./text-generation-webui/cache:/home/app/text-generation-webui/cache
      - ./text-generation-webui/characters:/home/app/text-generation-webui/characters
      - ./text-generation-webui/extensions:/home/app/text-generation-webui/extensions
      - ./text-generation-webui/loras:/home/app/text-generation-webui/loras
      - ./text-generation-webui/logs:/home/app/text-generation-webui/logs
      - ./text-generation-webui/models:/home/app/text-generation-webui/models
      - ./text-generation-webui/presets:/home/app/text-generation-webui/presets
      - ./text-generation-webui/prompts:/home/app/text-generation-webui/prompts
      - ./text-generation-webui/softprompts:/home/app/text-generation-webui/softprompts
      - ./text-generation-webui/training:/home/app/text-generation-webui/training
      - ./text-generation-webui/cloudflared:/etc/cloudflared
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['2']
              capabilities: [gpu]

  nvidia-prometheus:
    container_name: nvidia-prometheus
    restart: always
    user: 1000:1000
    image: utkuozdemir/nvidia_gpu_exporter:1.2.0
    volumes:
      - "/usr/lib/x86_64-linux-gnu/:/usr/lib/x86_64-linux-gnu/:ro"
      - "/usr/bin/nvidia-smi:/usr/bin/nvidia-smi"
    devices:
      - "/dev/nvidiactl:/dev/nvidiactl"
      - "/dev/nvidia0:/dev/nvidia0"
      - "/dev/nvidia1:/dev/nvidia1"
      - "/dev/nvidia2:/dev/nvidia2"
      - "/dev/nvidia3:/dev/nvidia3"
      - "/dev/nvidia4:/dev/nvidia4"
    ports:
      - 9835:9835
    deploy:
      resources:
        reservations:
           devices:
              - driver: nvidia
                capabilities: [gpu]
